{"no":[{"id":"0YPFo_","sz":{"w":86.34,"h":35},"co":"Metrics","po":{"c":{"x":0,"y":0}},"rd":[{"id":"rObWIu","sz":{"w":91.78,"h":32},"co":"Accuracy","br":{"r":1},"ch":[{"id":"N7ykZt","sz":{"w":162.84,"h":32},"co":"Overall correctness"},{"id":"_Idv85","sz":{"w":400,"h":56},"co":"How often the predictions are correct across all classes"},{"id":"nKq5IG","sz":{"w":400,"h":56},"co":"Out of all the predictions the AI model made, how many were right?"},{"id":"sJYnDJ","sz":{"w":400,"h":56},"co":"Generally, accuracy is reliable when handling balanced datasets"},{"id":"tFZluv","sz":{"w":255.31,"h":32},"co":"Acc = (TP+TN)/(TP+FP+TN+FN)"}]},{"id":"yjjfNE","sz":{"w":92.24,"h":32},"co":"Precision","br":{"r":2},"ch":[{"id":"n-uN_z","sz":{"w":255.78,"h":32},"co":"Reliability of positive predictions"},{"id":"Ws5kC6","sz":{"w":400,"h":56},"co":"Of all the instances predicted as positive, how many were correct?"},{"id":"0yUV3F","sz":{"w":129.83,"h":32},"co":"P=TP/(TP+FP)"}]},{"id":"coN1Ld","sz":{"w":69.21,"h":32},"co":"Recall","br":{"r":3},"ch":[{"id":"uCLb13","sz":{"w":350.23,"h":32},"co":"How well the model identifies actual positives"},{"id":"q2pexD","sz":{"w":340.24,"h":32},"co":"It is known as sensitivity or true positive rate"},{"id":"HbIiH2","sz":{"w":400,"h":56},"co":"Of all the actual positive instances, how many did the model detect correctly?"},{"id":"Rp-OhA","sz":{"w":130.91,"h":32},"co":"R=TP/(TP+FN)"}]},{"id":"jJvNnP","sz":{"w":178.13,"h":32},"co":"Precision-recall curve","br":{"r":7},"ch":[{"id":"Ob8vyZ","sz":{"w":400,"h":56},"co":"Shows how precision and recall change as the modelâ€™s decision threshold changes"},{"id":"FT72fR","sz":{"w":400,"h":56},"co":"Useful for imbalanced datasets, where one class is much less frequent"}]},{"id":"2WOj1H","sz":{"w":87.33,"h":32},"co":"F1 score","br":{"r":4},"ch":[{"id":"m9dSMk","sz":{"w":383.33,"h":32},"co":"Captures the balance between precision and recall"},{"id":"7s400Q","sz":{"w":400,"h":56},"co":"Useful when both false positives and false negatives matter"},{"id":"GCmdZS","sz":{"w":328.58,"h":32},"co":"F1 = (2*precision*recall)/(precision+recall)"}]},{"id":"wQ6NhU","sz":{"w":148.06,"h":32},"co":"Confusion matrix","br":{"r":5},"ch":[{"id":"cvrXk8","sz":{"w":400,"h":56},"co":"How many predictions were correct and the types of errors the model made"},{"id":"m46USP","sz":{"w":233.6,"h":32},"co":"Actual value - predicted value"}]},{"id":"tP4_KO","sz":{"w":190.1,"h":32},"co":"Intersection over Union","br":{"r":6},"ch":[{"id":"mq2cJD","sz":{"w":230.63,"h":32},"co":"Bounding box overlap quality"}]},{"id":"3ts38o","sz":{"w":225.3,"h":32},"co":"Average precision(AP/mAP)","br":{"r":8},"ch":[{"id":"iXm8nU","sz":{"w":400,"h":80},"co":"Detectors assign confidence scores. AP integrates precision and recall across thresholds, while mAP averages across classes"}]}]}],"se":{"b":{"c":"#375D81"}},"st":{"h":true,"d":3,"p":true,"i":"up"},"co":[]}